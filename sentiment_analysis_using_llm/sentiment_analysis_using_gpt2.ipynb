{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer,BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('twitter_training.csv')\n",
    "val_df = pd.read_csv('twitter_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Entity</th>\n",
       "      <th>labels</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_Id       Entity    labels  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "\n",
       "                                               texts  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Entity</th>\n",
       "      <th>labels</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3364</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_Id     Entity      labels  \\\n",
       "0      3364   Facebook  Irrelevant   \n",
       "1       352     Amazon     Neutral   \n",
       "2      8312  Microsoft    Negative   \n",
       "3      4371      CS-GO    Negative   \n",
       "4      4433     Google     Neutral   \n",
       "\n",
       "                                               texts  \n",
       "0  I mentioned on Facebook that I was struggling ...  \n",
       "1  BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "2  @Microsoft Why do I pay for WORD when it funct...  \n",
       "3  CSGO matchmaking is so full of closet hacking,...  \n",
       "4  Now the President is slapping Americans in the...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.iloc[:,2:]\n",
    "val_df = val_df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74682, 2), (1000, 2))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop_duplicates(inplace=True)\n",
    "train_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\"Negative\":0,\"Neutral\":1,\"Positive\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['labels'].isin(label_map.keys())] # Remove irrelevant labels\n",
    "train_df['labels'] = train_df['labels'].map(label_map)\n",
    "val_df = val_df[val_df['labels'].isin(label_map.keys())] # Remove irrelevant labels\n",
    "val_df['labels'] = val_df['labels'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57486, 2), (828, 2))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['labels', 'texts', '__index_level_0__'],\n",
       "     num_rows: 57486\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['labels', 'texts', '__index_level_0__'],\n",
       "     num_rows: 828\n",
       " }))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset,val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type=\"torch\", columns=[\"texts\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"texts\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1., 0., 2., 2., 2., 0., 2., 2., 0., 1., 0., 2., 2., 0., 2.,\n",
       "        0., 0., 1., 0., 1., 1., 0., 0., 2., 2., 0., 2., 0., 1., 1., 2., 1., 2.,\n",
       "        1., 1., 1., 2., 1., 0., 0., 0., 1., 2., 0., 0., 2., 2., 2., 2., 2., 0.,\n",
       "        0., 2., 2., 0., 1., 0., 1., 0., 2., 0., 0., 2., 2., 2., 1., 1., 1., 2.,\n",
       "        2., 1., 2., 1., 0., 0., 1., 1., 0., 2., 0., 0., 0., 1., 2., 1., 0., 2.,\n",
       "        2., 1., 2., 1., 2., 0., 1., 1., 1., 0., 1., 0., 1., 1., 2., 2., 1., 0.,\n",
       "        0., 2., 0., 1., 0., 2., 1., 0., 1., 2., 1., 2., 2., 1., 1., 1., 1., 2.,\n",
       "        1., 2., 2., 0., 1., 1., 1., 1., 0., 1., 2., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        2., 2., 2., 1., 1., 2., 1., 1., 1., 2., 1., 0., 0., 1., 2., 2., 1., 2.,\n",
       "        2., 1., 1., 0., 0., 0., 0., 2., 1., 1., 2., 2., 2., 2., 0., 2., 2., 1.,\n",
       "        0., 0., 0., 2., 2., 0., 0., 2., 2., 0., 2., 2., 0., 2., 1., 0., 1., 1.,\n",
       "        2., 0., 2., 2., 1., 2., 0., 0., 2., 2., 2., 2., 1., 1., 2., 0., 1., 2.,\n",
       "        1., 0., 1., 1., 0., 2., 2., 0., 1., 2., 1., 0., 1., 0., 2., 2., 0., 0.,\n",
       "        0., 2., 0., 1., 2., 1., 1., 0., 2., 0., 2., 0., 1., 1., 2., 0., 1., 0.,\n",
       "        2., 0., 2., 2., 2., 2., 2., 2., 0., 0., 2., 0., 1., 1., 1., 2., 1., 2.,\n",
       "        0., 1., 1., 1., 1., 0., 2., 0., 0., 2., 2., 1., 1., 0., 0., 0., 1., 2.,\n",
       "        1., 0., 2., 1., 0., 0., 0., 2., 1., 1., 0., 2., 2., 1., 2., 1., 1., 2.,\n",
       "        2., 0., 1., 2., 0., 1., 0., 0., 2., 2., 2., 2., 1., 0., 1., 2., 1., 2.,\n",
       "        0., 0., 0., 2., 1., 2., 0., 1., 0., 2., 2., 2., 2., 1., 1., 1., 0., 2.,\n",
       "        2., 1., 0., 2., 1., 0., 0., 0., 0., 0., 1., 1., 1., 2., 2., 0., 0., 1.,\n",
       "        0., 1., 1., 0., 2., 0., 2., 2., 2., 1., 2., 1., 1., 0., 2., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 2., 2., 1., 0., 0., 2., 2., 0., 2., 2., 2.,\n",
       "        2., 2., 1., 0., 2., 1., 1., 2., 2., 2., 2., 1., 0., 0., 0., 0., 1., 2.,\n",
       "        0., 0., 2., 2., 1., 1., 0., 0., 2., 1., 0., 0., 0., 1., 1., 2., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 2., 0., 1., 0., 1., 2., 0., 1., 2., 2., 0., 1.,\n",
       "        1., 2., 0., 0., 1., 1., 0., 2., 0., 1., 0., 0., 0., 2., 0., 2., 0., 2.,\n",
       "        0., 0., 1., 0., 1., 0., 2., 0., 1., 0., 0., 1., 1., 2., 0., 2., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 0., 1., 2., 1., 1., 0., 1., 2., 1., 1., 1.,\n",
       "        1., 1., 2., 1., 2., 2., 2., 1., 0., 2., 1., 1., 0., 2., 1., 1., 0., 1.,\n",
       "        0., 1., 2., 0., 2., 0., 0., 1., 1., 1., 1., 2., 2., 2., 0., 0., 1., 2.,\n",
       "        1., 1., 0., 2., 2., 1., 2., 0., 0., 1., 2., 0., 2., 0., 1., 2., 2., 1.,\n",
       "        1., 1., 2., 1., 0., 1., 1., 0., 2., 0., 1., 2., 2., 2., 2., 1., 0., 1.,\n",
       "        2., 2., 2., 2., 2., 0., 1., 2., 1., 1., 0., 0., 0., 1., 2., 1., 0., 2.,\n",
       "        2., 2., 1., 2., 0., 1., 0., 1., 0., 1., 1., 2., 0., 2., 2., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 2., 2., 2., 2., 1., 0., 0., 2., 0., 0., 1., 1., 2., 1.,\n",
       "        0., 1., 2., 0., 1., 2., 0., 1., 1., 2., 0., 1., 0., 2., 2., 1., 2., 1.,\n",
       "        2., 0., 1., 1., 1., 2., 1., 1., 0., 2., 1., 0., 0., 1., 1., 2., 0., 0.,\n",
       "        0., 0., 2., 1., 1., 2., 1., 0., 2., 2., 0., 2., 2., 1., 0., 1., 2., 2.,\n",
       "        0., 0., 0., 2., 0., 1., 0., 1., 1., 2., 2., 0., 1., 2., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 1., 1., 1., 2., 1., 1., 1., 0., 1., 2., 1., 0.,\n",
       "        0., 2., 1., 2., 1., 2., 1., 0., 2., 2., 2., 2., 0., 0., 2., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 2., 0., 1., 2., 1., 0., 2., 2., 0., 2., 1.,\n",
       "        1., 2., 0., 1., 0., 1., 2., 2., 1., 0., 2., 0., 0., 1., 0., 1., 0., 2.,\n",
       "        1., 0., 0., 2., 2., 0., 1., 0., 1., 1., 1., 1., 1., 1., 2., 1., 2., 2.,\n",
       "        2., 0., 1., 2., 1., 2., 1., 2., 1., 2., 1., 0., 0., 2., 2., 2., 2., 1.,\n",
       "        0., 2., 2., 0., 0., 0., 1., 2., 1., 2., 2., 1., 2., 0., 2., 2., 2., 1.],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['labels'].to(torch.float64)\n",
    "val_dataset['labels'].to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(2),\n",
       " 'texts': 'im getting on borderlands and i will murder you all ,'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'openai-community/gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"texts\"], padding=\"max_length\", truncation=True,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23948ba0ae7340a78d0ce62dcab013c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/57486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67856fadea6e4c02ad35751b0b6b8203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/828 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(lambda x: {\"texts\": str(x[\"texts\"])})\n",
    "val_dataset = val_dataset.map(lambda x: {\"texts\": str(x[\"texts\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bbacc12f584c449b6118fb2c133023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/57486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8e5b331dc045d5b3002910e1dab64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/828 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(2),\n",
       " 'texts': 'im getting on borderlands and i will murder you all ,',\n",
       " 'input_ids': tensor([  320,  1972,   319,  4865,  4447,   290,  1312,   481,  5123,   345,\n",
       "           477,   837, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=4,  \n",
    "    lora_alpha=16,  \n",
    "    lora_dropout=0.1,  \n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"c_attn\", \"c_proj\"]  # LoRA applied to attention layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 407,808 || all params: 124,849,920 || trainable%: 0.3266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Divyansh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Divyansh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    per_device_train_batch_size=8,  # Reduce for Colab Free\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=1,  # Increase if Colab Pro\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,  # Mixed Precision for Memory Efficiency\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(p):\n",
    "    preds, labels = p\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(labels, preds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Divyansh\\AppData\\Local\\Temp\\ipykernel_25476\\2814646100.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7186' max='7186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7186/7186 7:49:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.048000</td>\n",
       "      <td>0.948839</td>\n",
       "      <td>0.560386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.865800</td>\n",
       "      <td>0.818894</td>\n",
       "      <td>0.632850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.802500</td>\n",
       "      <td>0.782820</td>\n",
       "      <td>0.665459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.786335</td>\n",
       "      <td>0.665459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.788900</td>\n",
       "      <td>0.774365</td>\n",
       "      <td>0.676329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.774400</td>\n",
       "      <td>0.762390</td>\n",
       "      <td>0.675121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.784800</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.679952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7186, training_loss=0.83616247477055, metrics={'train_runtime': 28164.0601, 'train_samples_per_second': 2.041, 'train_steps_per_second': 0.255, 'total_flos': 3773264574283776.0, 'train_loss': 0.83616247477055, 'epoch': 1.0})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_model/gpt_sentiment_tokenizer\\\\tokenizer_config.json',\n",
       " 'saved_model/gpt_sentiment_tokenizer\\\\special_tokens_map.json',\n",
       " 'saved_model/gpt_sentiment_tokenizer\\\\vocab.json',\n",
       " 'saved_model/gpt_sentiment_tokenizer\\\\merges.txt',\n",
       " 'saved_model/gpt_sentiment_tokenizer\\\\added_tokens.json',\n",
       " 'saved_model/gpt_sentiment_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained('saved_model/gpt_sentiment_model')\n",
    "tokenizer.save_pretrained('saved_model/gpt_sentiment_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('saved_model/gpt_sent_trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'saved_model/gpt_sentiment_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model with Example Texts\n",
    "def evaluate_example_texts(texts, true_labels):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct, total = 0, 0\n",
    "    label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text, true_label in zip(texts, true_labels):\n",
    "            inputs = tokenizer(text, truncation=True, return_tensors='pt')\n",
    "            # input_ids, attention_mask = inputs[\"input_ids\"].to(device), inputs[\"attention_mask\"].to(device)\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            pred_label =  torch.argmax(outputs.logits,dim=1) # Placeholder logic for sentiment extraction from Llama output\n",
    "            print(f\"Text: {text}\\nPredicted Sentiment: {label_map[pred_label.item()]} (Actual: {label_map[true_label]})\\n\")\n",
    "            if pred_label == true_label:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"This is the worst service I've ever received.\",truncation=True,return_tensors='pt')\n",
    "true_label=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(outputs.logits,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love this product! It works perfectly.\n",
      "Predicted Sentiment: Positive (Actual: Positive)\n",
      "\n",
      "Text: This is the worst service I've ever received.\n",
      "Predicted Sentiment: Negative (Actual: Negative)\n",
      "\n",
      "Text: The movie was okay, nothing special but not bad either.\n",
      "Predicted Sentiment: Positive (Actual: Neutral)\n",
      "\n",
      "Evaluation Accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# Test Example Texts\n",
    "test_texts = [\n",
    "    \"I love this product! It works perfectly.\",\n",
    "    \"This is the worst service I've ever received.\",\n",
    "    \"The movie was okay, nothing special but not bad either.\"\n",
    "]\n",
    "test_labels = [2, 0, 1]  # Expected sentiments: Positive, Negative, Neutral\n",
    "evaluate_example_texts(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
